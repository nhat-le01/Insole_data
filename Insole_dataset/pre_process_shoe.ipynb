{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "COLUMNS_NAME = [\"Date\", \"Sensor_1_left\", \"Sensor_2_left\",\"Sensor_3_left\", \"Sensor_4_left\", \"Sensor_5_left\", \"Sensor_6_left\", \"Sensor_7_left\", \"Sensor_8_left\",\n",
    "               \"Acc_x_left\", \"Acc_y_left\", \"Acc_z_left\", \"Gyzo_x_left\", \"Gyzo_y_left\", \"Gyzo_z_left\",\n",
    "               \"Sensor_1_right\", \"Sensor_2_right\",\"Sensor_3_right\", \"Sensor_4_right\", \"Sensor_5_right\", \"Sensor_6_right\", \"Sensor_7_right\", \"Sensor_8_right\",\n",
    "               \"Acc_x_right\", \"Acc_y_right\", \"Acc_z_right\", \"Gyzo_x_right\", \"Gyzo_y_right\", \"Gyzo_z_right\"]\n",
    "#print(len(COLUMNS_NAME))\n",
    "LIST_OF_ACTIONS = [None, \"Walking\", \"Uphill Walking\", \"Downhill Walking\", \"Going Up Stairs\", \"Going Down Stairs\", \"Running\", \"Walking Fast\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\01', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\02', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\03', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\04', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\05', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\06', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\07', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\08', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\09', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\10', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\11', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\12', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\13', 'C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\14']\n"
     ]
    }
   ],
   "source": [
    "def get_file_paths(path):\n",
    "    \"\"\"\n",
    "    Return a list of direction of files in current path contains names of file in the direction\n",
    "    \"\"\"\n",
    "    return [os.path.join(path, p) for p in os.listdir(path)]\n",
    "PATH = \"C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\"\n",
    "#print(os.listdir(PATH))\n",
    "PATH1= \"C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\09\"\n",
    "#print(get_file_paths(path1)[0])\n",
    "def get_file_names(path):\n",
    "    \"\"\"\n",
    "    return paths of files under this input path\n",
    "    \"\"\"\n",
    "    #paths = get_file_paths(path)\n",
    "    return os.listdir(path)\n",
    "print(get_file_paths(PATH))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_up_table_for_each_person(path, list_of_actions):\n",
    "    \"\"\"\n",
    "    return a dictionary with keys: Walking, Uphill Walking, Downhill Walking, Going Up Stairs, Going Down Stairs, \n",
    "    Running, Walking Fast\n",
    "    that maps to walking data, uphill waking data, downhill walking data, goint up stairs data, going down stairs data,... etc\n",
    "    \"\"\"\n",
    "    #file_names = [os.path.splitext(file)[0] for file in file_names]\n",
    "    file_names = get_file_names(path)\n",
    "    file_paths = get_file_paths(path)\n",
    "    #print(files_names)\n",
    "    look_up = {}\n",
    "    for i in range(len(file_names)):\n",
    "        file = file_names[i]\n",
    "        file_path = file_paths[i]\n",
    "        #print(file_path)\n",
    "        not_extension = os.path.splitext(file)[0]\n",
    "        user_id = int(not_extension.split(\"_\")[0])\n",
    "        n = int(not_extension.split(\"_\")[1])\n",
    "        #print(n)\n",
    "        #print(file)\n",
    "        data = pd.read_csv(file_path, names = COLUMNS_NAME)\n",
    "        data = data.drop(data.index[0])\n",
    "        #Insert a user_id column and an action column\n",
    "        data.insert(0, \"User_id\", user_id)\n",
    "        data.insert(1, \"Action\", list_of_actions[n])\n",
    "        look_up[list_of_actions[n]] = data\n",
    "    return look_up\n",
    "table = look_up_table_for_each_person(PATH1, LIST_OF_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Action</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sensor_1_left</th>\n",
       "      <th>Sensor_2_left</th>\n",
       "      <th>Sensor_3_left</th>\n",
       "      <th>Sensor_4_left</th>\n",
       "      <th>Sensor_5_left</th>\n",
       "      <th>Sensor_6_left</th>\n",
       "      <th>Sensor_7_left</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor_5_right</th>\n",
       "      <th>Sensor_6_right</th>\n",
       "      <th>Sensor_7_right</th>\n",
       "      <th>Sensor_8_right</th>\n",
       "      <th>Acc_x_right</th>\n",
       "      <th>Acc_y_right</th>\n",
       "      <th>Acc_z_right</th>\n",
       "      <th>Gyzo_x_right</th>\n",
       "      <th>Gyzo_y_right</th>\n",
       "      <th>Gyzo_z_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>Walking</td>\n",
       "      <td>'2017-08-02 19:33:25.724</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-211</td>\n",
       "      <td>438</td>\n",
       "      <td>-8740</td>\n",
       "      <td>6</td>\n",
       "      <td>-21</td>\n",
       "      <td>-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Walking</td>\n",
       "      <td>'2017-08-02 19:33:25.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-197</td>\n",
       "      <td>395</td>\n",
       "      <td>-8698</td>\n",
       "      <td>3</td>\n",
       "      <td>-17</td>\n",
       "      <td>-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Walking</td>\n",
       "      <td>'2017-08-02 19:33:25.744</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-201</td>\n",
       "      <td>406</td>\n",
       "      <td>-8704</td>\n",
       "      <td>-2</td>\n",
       "      <td>-34</td>\n",
       "      <td>-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Walking</td>\n",
       "      <td>'2017-08-02 19:33:25.754</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-197</td>\n",
       "      <td>419</td>\n",
       "      <td>-8713</td>\n",
       "      <td>2</td>\n",
       "      <td>-26</td>\n",
       "      <td>-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>Walking</td>\n",
       "      <td>'2017-08-02 19:33:25.764</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-199</td>\n",
       "      <td>404</td>\n",
       "      <td>-8685</td>\n",
       "      <td>-2</td>\n",
       "      <td>-26</td>\n",
       "      <td>-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>Walking</td>\n",
       "      <td>'2017-08-02 19:33:25.774</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-225</td>\n",
       "      <td>375</td>\n",
       "      <td>-8707</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>-42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Walking</td>\n",
       "      <td>'2017-08-02 19:33:25.784</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-200</td>\n",
       "      <td>453</td>\n",
       "      <td>-8692</td>\n",
       "      <td>-19</td>\n",
       "      <td>34</td>\n",
       "      <td>-38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id   Action                      Date Sensor_1_left Sensor_2_left  \\\n",
       "1        9  Walking  '2017-08-02 19:33:25.724             1             0   \n",
       "2        9  Walking  '2017-08-02 19:33:25.734             1             0   \n",
       "3        9  Walking  '2017-08-02 19:33:25.744             1             0   \n",
       "4        9  Walking  '2017-08-02 19:33:25.754             1             0   \n",
       "5        9  Walking  '2017-08-02 19:33:25.764             1             0   \n",
       "6        9  Walking  '2017-08-02 19:33:25.774             1             0   \n",
       "7        9  Walking  '2017-08-02 19:33:25.784             1             0   \n",
       "\n",
       "  Sensor_3_left Sensor_4_left Sensor_5_left Sensor_6_left Sensor_7_left  \\\n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "5             0             0             0             0             0   \n",
       "6             0             0             0             0             0   \n",
       "7             0             0             0             0             0   \n",
       "\n",
       "      ...      Sensor_5_right Sensor_6_right Sensor_7_right Sensor_8_right  \\\n",
       "1     ...                   0              1              1              1   \n",
       "2     ...                   0              1              1              1   \n",
       "3     ...                   0              1              1              1   \n",
       "4     ...                   0              1              1              1   \n",
       "5     ...                   0              1              1              1   \n",
       "6     ...                   0              1              1              1   \n",
       "7     ...                   0              1              1              1   \n",
       "\n",
       "  Acc_x_right Acc_y_right Acc_z_right Gyzo_x_right Gyzo_y_right Gyzo_z_right  \n",
       "1        -211         438       -8740            6          -21          -44  \n",
       "2        -197         395       -8698            3          -17          -40  \n",
       "3        -201         406       -8704           -2          -34          -36  \n",
       "4        -197         419       -8713            2          -26          -44  \n",
       "5        -199         404       -8685           -2          -26          -37  \n",
       "6        -225         375       -8707           -1            9          -42  \n",
       "7        -200         453       -8692          -19           34          -38  \n",
       "\n",
       "[7 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = table[\"Walking\"]\n",
    "df.head(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_fast = table[\"Walking Fast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_interval(look_up_table):\n",
    "    \"\"\"\n",
    "    Add a column named interval to the table, for each person, the amount of time he/she does the action is as follow\n",
    "    3 minutes: walking\n",
    "    2 minutes: uphill walking\n",
    "    2 minutes: downhill walking\n",
    "    1 minutes: going up stairs\n",
    "    1 minutes: going down stairs\n",
    "    3 minutes: running\n",
    "    3 minutes: walking fast\n",
    "    \n",
    "    \"\"\"\n",
    "    for key in look_up_table:\n",
    "        #num_rows = look_up_table.shape[0]\n",
    "        current_action_data = look_up_table[key]\n",
    "        num_rows = current_action_data.shape[0]\n",
    "        start_time = [parse(current_action_data.iloc[0, 2])] * num_rows\n",
    "        end_time = [parse(date_time) for date_time in current_action_data.iloc[:, 2]]\n",
    "        delta = [end_time[i] - start_time[i] for i in range(len(start_time))]\n",
    "        delta = [diff.total_seconds() for diff in delta]\n",
    "        current_action_data.insert(3, \"Interval\", delta, allow_duplicates = False)\n",
    "    return look_up_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_each_person(paths):\n",
    "    \"\"\"\n",
    "    return a table that maps key (1, 2, 3, ... , 14) to data frame that contains information about that corresponding person\n",
    "    \"\"\"\n",
    "    current_person = 1\n",
    "    look_up_table_for_everyone = {}\n",
    "    for path in paths:\n",
    "        print(path)\n",
    "        look_up = look_up_table_for_each_person(path, LIST_OF_ACTIONS)\n",
    "        #look_up_table_for_each_person[key].dropna() for key in look_up_table_for_each_person\n",
    "        for key in look_up:\n",
    "            look_up[key] = look_up[key].dropna()\n",
    "        new_table = add_interval(look_up)\n",
    "        individual_data = pd.concat([new_table[key] for key in new_table], axis = 0, ignore_index = True)\n",
    "        look_up_table_for_everyone[current_person] = individual_data\n",
    "        current_person += 1\n",
    "    return look_up_table_for_everyone\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\01\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\02\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\03\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\04\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\05\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\06\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\07\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\08\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\09\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\10\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\11\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\12\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\13\n",
      "C:\\Users\\nhatl\\Desktop\\Insole_dataset\\Insole_dataset\\14\n"
     ]
    }
   ],
   "source": [
    "#data_for_second_person = get_data_for_each_person(\"C:\\\\Users\\\\nhatl\\\\Desktop\\\\Insole_dataset\\\\Insole_dataset\\\\02\")\n",
    "paths = get_file_paths(PATH)\n",
    "final = get_data_for_each_person(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(COLUMNS_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final[1].head(20000)\n",
    "#array = final[1].values\n",
    "final_dataset = pd.concat([final[key] for key in final], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = final_dataset[\"Action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1273444, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precisionAndRecall(predictions, correctedLabels):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for i in range(len(predictions)):\n",
    "        if (predictions[i] == 1 and correctedLabels[i, 0] == 1):\n",
    "            tp += 1\n",
    "        if (predictions[i] == 1 and correctedLabels[i, 0] == 0):\n",
    "            fp += 1\n",
    "        if (predictions[i] == 0 and correctedLabels[i, 0] == 1):\n",
    "            fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return precision, recall\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = final_dataset.drop([\"Action\", \"Date\", \"User_id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X_train_scale = scale(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1273444, 1, 29, 1)\n",
      "(1273444, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train_scale = X_train_scale.reshape(X_train_scale.shape[0], 1, X_train_scale.shape[1], 1)\n",
    "print(X_train_scale.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c913a87f60>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train_scale[2][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhatl\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(853207, 1, 29, 1)\n",
      "WARNING:tensorflow:From C:\\Users\\nhatl\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 682565 samples, validate on 170642 samples\n",
      "WARNING:tensorflow:From C:\\Users\\nhatl\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "682565/682565 [==============================] - 494s 724us/sample - loss: 0.5415 - acc: 0.8075 - val_loss: 0.4050 - val_acc: 0.8620\n",
      "Epoch 2/5\n",
      "522000/682565 [=====================>........] - ETA: 1:42 - loss: 0.3757 - acc: 0.8707"
     ]
    }
   ],
   "source": [
    "#X_train = final_dataset.drop([\"Action\", \"Date\", \"User_id\"], axis = 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "recall_X_val = []\n",
    "precision_Y_val = []\n",
    "\n",
    "shuffled_X_train, shuffled_X_test, shuffled_Y_train, shuffled_Y_test = train_test_split(X_train_scale, Y_train, test_size=0.33)\n",
    "        #now we have to split the shuffled_X 70/30\n",
    "model = Sequential()\n",
    "print(shuffled_X_train.shape)\n",
    "    \n",
    "    #64,(3,3)\n",
    "#layer = Conv2D(64, (1, 1), activation = \"relu\", input_shape = (1, 29, 1))\n",
    "#print(type(layer))\n",
    "    \n",
    "model.add(Conv2D(32, (1, 1), activation = \"relu\", input_shape = (1, 29, 1)))\n",
    "#model.add(Conv2D(filters = 32, kernel_size = (1, 1), padding = \"Same\",\n",
    "                # = \"relu\", input_shape = (1, 29, 1)))\n",
    "\n",
    "model.add(MaxPool2D(pool_size = (1, 1)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (1,1),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "#model.add(Conv2D(filters = 64, kernel_size = (1,1),padding = 'Same', \n",
    "                    # activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (1, 1), padding = \"Same\",\n",
    "                    activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size= (1, 1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation = \"softmax\"))\n",
    "    \n",
    "    \n",
    "optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(shuffled_X_train, shuffled_Y_train, epochs=5, batch_size = 50, validation_split=0.2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = model.predict(shuffled_X_test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "#results = np.argmax(results,axis = 1)\n",
    "import numpy as np\n",
    "results = model.predict(shuffled_X_test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_Y_test[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = []\n",
    "for i in range(len(shuffled_Y_test)):\n",
    "    for j in range(len(shuffled_Y_test[0])):\n",
    "        if shuffled_Y_test[i][j] == 1:\n",
    "            Y_test.append(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test[6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = len(Y_test)\n",
    "corrected_predictions = 0\n",
    "#print(shuffled_X_test.shape)\n",
    "for i in range(num_examples):\n",
    "    if Y_test[i] == results[i]:\n",
    "        corrected_predictions += 1\n",
    "print(corrected_predictions/ num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
